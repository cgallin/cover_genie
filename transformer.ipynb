{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_data/job_postings_data/postings.csv\")\n",
    "map = pd.read_csv(\"raw_data/job_postings_data/mappings/industries.csv\")\n",
    "industries = pd.read_csv(\"raw_data/job_postings_data/jobs/job_industries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_map = {\n",
    "    \"Technology\": [\n",
    "        \"Defense and Space Manufacturing\", \"Computer Hardware Manufacturing\",\n",
    "        \"Software Development\", \"Computer Networking Products\",\n",
    "        \"Technology, Information and Internet\",\n",
    "        \"Telecommunications\", \"IT Services and IT Consulting\",\n",
    "        \"Internet Marketplace Platforms\", \"Blockchain Services\",\n",
    "        \"Desktop Computing Software Products\", \"IT System Custom Software Development\",\n",
    "        \"Data Infrastructure and Analytics\", \"Social Networking Platforms\",\n",
    "        \"Business Intelligence Platforms\", \"Digital Accessibility Services\",\n",
    "        \"Internet News\", \"Internet Publishing\",\"Technology and Software\",\"Technology, Information and Media\",\n",
    "        \"Information Technology and Services\", \"Computer Software\", \"Computer Networking\",\"Computer and Network Security\",\n",
    "        \"IT System Data Services\",\"IT System Data Services\",\"IT System Testing and Evaluation\",\n",
    "        \"Information Services\",\"Computer Games\",\"Computer Hardware\",\"Computer Networking Products\",\n",
    "\n",
    "    ],\n",
    "    \"Manufacturing\": [\n",
    "        \"Consumer Electronics\", \"Medical Equipment Manufacturing\",\n",
    "        \"Apparel Manufacturing\", \"Footwear Manufacturing\",\n",
    "        \"Textile Manufacturing\", \"Furniture and Home Furnishings Manufacturing\",\n",
    "        \"Beverage Manufacturing\", \"Pharmaceutical Manufacturing\",\n",
    "        \"Sporting Goods Manufacturing\", \"Tobacco Manufacturing\",\n",
    "        \"Plastics and Rubber Product Manufacturing\", \"Packaging and Containers Manufacturing\",\n",
    "        \"Glass, Ceramics and Concrete Manufacturing\", \"Metal Valve, Ball, and Roller Manufacturing\",\n",
    "        \"Robot Manufacturing\", \"Industrial Automation\",\n",
    "        \"Transportation Equipment Manufacturing\", \"Oil and Gas\",\n",
    "        \"Shipbuilding\", \"Chemical Manufacturing\", \"Mining\",\n",
    "        \"Agricultural Chemical Manufacturing\", \"Paint, Coating, and Adhesive Manufacturing\",\n",
    "        \"Electric Lighting Equipment Manufacturing\", \"Meat Products Manufacturing\",\n",
    "        \"Wood Product Manufacturing\", \"Food and Beverage Manufacturing\",\n",
    "        \"Machinery Manufacturing\", \"Construction Hardware Manufacturing\",\n",
    "        \"Primary Metal Manufacturing\", \"Fabricated Metal Products\",\n",
    "        \"HVAC and Refrigeration Equipment Manufacturing\",\n",
    "        \"Engines and Power Transmission Equipment Manufacturing\",\"Motor Vehicle Manufacturing\",\n",
    "        \"Aerospace and Defense Manufacturing\", \"Electrical Equipment Manufacturing\",\n",
    "        \"Aviation and Aerospace Component Manufacturing\",\"Information Technology & Services\",\n",
    "        \"Agriculture, Construction, Mining Machinery Manufacturing\",\"Motor Vehicle Parts Manufacturing\",\n",
    "        \"Renewable Energy Equipment Manufacturing\",\"Semiconductor Manufacturing\",\n",
    "        \"Magnetic and Optical Media Manufacturing\",\n",
    "        \"Communications Equipment Manufacturing\", \"Audio and Video Equipment Manufacturing\",\n",
    "        \"Renewable Energy Semiconductor Manufacturing\",\"Mattress and Blinds Manufacturing\",\n",
    "        \"Household and Institutional Furniture Manufacturing\",\"Abrasives and Nonmetallic Minerals Manufacturing\",\n",
    "        \"Industrial Machinery Manufacturing\",\"Appliances, Electrical, and Electronics Manufacturing\",\n",
    "        \"Automation Machinery Manufacturing\", \"Computers and Electronics Manufacturing\",\"Plastics Manufacturing\",\n",
    "\n",
    "    ],\n",
    "    \"Healthcare and Biotechnology\": [\n",
    "        \"Medical Practices\", \"Hospitals and Health Care\",\n",
    "        \"Biotechnology Research\", \"Mental Health Care\",\n",
    "        \"Medical Device\", \"Veterinary Services\", \"Nursing Homes and Residential Care Facilities\",\n",
    "        \"Animal Feed Manufacturing\", \"Physical, Occupational and Speech Therapists\",\n",
    "        \"Alternative Medicine\", \"Personal Care Product Manufacturing\",\n",
    "        \"Cosmetics\", \"Pharmaceutical Manufacturing\", \"Dentists\",\n",
    "        \"Medical and Diagnostic Laboratories\", \"Home Health Care Services\",\"Health and Human Services\",\n",
    "        \"Healthcare Services and Hospitals\",\"Biotechnology\",\"Pharmaceuticals\",\n",
    "        \"Medical Devices\",\"Healthcare Information Technology\",\"Public Health\",\"Hospitals\",\n",
    "\n",
    "    ],\n",
    "    \"Legal and Consulting Services\": [\n",
    "        \"Law Practice\", \"Legal Services\", \"Business Consulting and Services\",\n",
    "        \"Government Relations Services\", \"Strategic Management Services\",\n",
    "        \"Alternative Dispute Resolution\", \"Public Policy Offices\",\n",
    "        \"Environmental Services\", \"Operations Consulting\",\n",
    "    ],\n",
    "    \"Finance, Banking, Insurance and Accounting\": [\n",
    "        \"Banking\", \"Insurance\", \"Real Estate\",\n",
    "        \"Investment Banking\", \"Investment Management\", \"Capital Markets\",\n",
    "        \"Venture Capital and Private Equity Principals\", \"Mortgage Services\",\n",
    "        \"Credit Intermediation\", \"Loan Brokers\", \"Pension Funds\",\n",
    "        \"Funds and Trusts\", \"Trusts and Estates\",\"Accounting\"\n",
    "    ],\n",
    "    \"Real Estate, Property Management, and Construction\": [\n",
    "         \"Leasing Non-residential Real Estate\",\"Custruction\",\"Real Estate\",\n",
    "        \"Property Management\",\n",
    "    ],\n",
    "    \"Consumer Goods and Retail\": [\n",
    "        \"Retail Apparel and Fashion\", \"Retail Groceries\", \"Retail Luxury Goods and Jewelry\",\n",
    "        \"Online and Mail Order Retail\", \"Retail Motor Vehicles\", \"Retail Office Supplies and Gifts\",\n",
    "        \"Retail Recyclable Materials & Used Merchandise\", \"Food and Beverage Retail\",\n",
    "        \"Sporting Goods Manufacturing\", \"Retail Musical Instruments\",\n",
    "        \"Retail Books and Printed News\", \"Retail Florists\", \"Tobacco Manufacturing\",\n",
    "        \"Wholesale Import and Export\", \"Wholesale Luxury Goods and Jewelry\",\n",
    "        \"Wholesale Food and Beverage\", \"Wholesale Chemical and Allied Products\",\n",
    "        \"Wholesale Raw Farm Products\",\"Retail\",\"Retail Health and Personal Care Products\",\n",
    "        \"Retail Pharmacies\"\n",
    "    ],\n",
    "    \"Entertainment and Media\": [\n",
    "        \"Entertainment Providers\", \"Movies, Videos, and Sound\",\n",
    "        \"Broadcast Media Production and Distribution\", \"Performing Arts\",\n",
    "        \"Gambling Facilities and Casinos\", \"Artists and Writers\", \"Online Audio and Video Media\",\n",
    "        \"Museums, Historical Sites, and Zoos\", \"Spectator Sports\",\n",
    "        \"Golf Courses and Country Clubs\", \"Amusement Parks and Arcades\",\n",
    "        \"Animation and Post-production\", \"Media Production\", \"Online Media\",\n",
    "        \"Writers and Editors\", \"Theater Companies\",\"Performing Arts and Spectator Sports\",\n",
    "    ],\n",
    "    \"Transportation and Logistics\": [\n",
    "        \"Freight and Package Transportation\", \"Truck Transportation\",\n",
    "        \"Rail Transportation\", \"Airlines and Aviation\", \"Urban Transit Services\",\n",
    "        \"Transportation/Trucking/Railroad\", \"Pipeline Transportation\",\n",
    "        \"Warehousing and Storage\", \"Ground Passenger Transportation\",'Transportation, Logistics, Supply Chain and Storage',\n",
    "\n",
    "    ],\n",
    "    \"Education and Research\": [\n",
    "        \"Primary and Secondary Education\", \"Higher Education\",\n",
    "        \"Education Administration Programs\", \"Research Services\",\n",
    "        \"Think Tanks\", \"Technical and Vocational Training\",\n",
    "        \"Non-profit Organizations\", \"Philanthropic Fundraising Services\",\"Education\",\n",
    "        \"E-Learning Providers\",\"Education Management\"\n",
    "    ],\n",
    "    \"Government and Public Administration\": [\n",
    "        \"Government Administration\", \"Public Safety\", \"Legislative Offices\",\n",
    "        \"International Affairs\", \"Military and International Affairs\",\n",
    "        \"Administration of Justice\", \"Public Policy Offices\",\n",
    "        \"Courts of Law\", \"Correctional Institutions\", \"Housing Programs\",\"Armed Forces\",\n",
    "        \"Law Enforcement\",\"Public Administration\",\"Public Safety\",\"International Affairs\",\n",
    "\n",
    "    ],\n",
    "    \"Environmental and Renewable Energy\": [\n",
    "        \"Environmental Services\", \"Horticulture\", \"Renewables & Environment\",\n",
    "        \"Solar Electric Power Generation\", \"Climate Data and Analytics\",\n",
    "        \"Wind Electric Power Generation\", \"Climate Technology Product Manufacturing\",\n",
    "        \"Conservation Programs\",\n",
    "    ],\n",
    "    \"Construction and Real Estate Development\": [\n",
    "        \"Building Construction\", \"Residential Building Construction\",\n",
    "        \"Nonresidential Building Construction\", \"Utility System Construction\",\n",
    "        \"Specialty Trade Contractors\", \"Architecture and Planning\",\n",
    "        \"Surveying and Mapping Services\", \"Civil Engineering\",\"Construction and Real Estate Development\",\n",
    "        \"Wholesale Building Materials\",\"Construction\",\"Water, Waste, Steam, and Air Conditioning Services\",\n",
    "    ],\n",
    "    \"Hospitality, Travel, and Food Service\" : [\n",
    "        \"Restaurants and Food Service\", \"Hospitality\", \"Food Production\",\n",
    "        \"Food and Beverage Manufacturing\", \"Food and Beverage Retail\",\"Restaurants\",\n",
    "        \"Food Production\", \"Food & Beverages\", \"Travel Arrangements\",\"Food and Beverage Services\",\n",
    "        \"Bed-and-Breakfasts, Hostels, Homestays\",\"Wineries\", \"Caterers\",\"Events Services\",\n",
    "\n",
    "    ],\n",
    "    \"Ambiguous or Placeholder Entries\": [\n",
    "        \"nan\", \"Programs\", \"Non-descriptive placeholders from the list\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "list=industry_map.values()\n",
    "industry_list=len(flatten(list))\n",
    "# Create a reverse mapping from industry names to their corresponding keys\n",
    "reverse_industry_map = {industry: key for key, industries in industry_map.items() for industry in industries}\n",
    "reverse_industry_map[\"nan\"]\n",
    "# Replace the values in map.industry_name with their \"corresponding keys\n",
    "map[\"sub_industry_name\"]=map[\"industry_name\"]\n",
    "map[\"industry_name\"]=map['industry_name'].map(lambda x : reverse_industry_map[x] if x in reverse_industry_map.keys() else x)\n",
    "df = df.merge(industries.merge(map,how=\"left\", on =\"industry_id\").set_index(\"industry_id\"),how=\"left\", on =\"job_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_industries=df.industry_name.value_counts()[df.industry_name.value_counts()>1000].index.tolist()\n",
    "df_filtered = df[df['industry_name'].isin(big_industries)]\n",
    "df_filtered= df_filtered.dropna(subset=[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "encoder= LabelEncoder()\n",
    "encoder.fit(df_filtered[\"industry_name\"])\n",
    "y_enc = encoder.transform(df_filtered[\"industry_name\"])\n",
    "y=to_categorical(y_enc)\n",
    "X=tokenizer(df_filtered[\"description\"].tolist(),padding=True,truncation=True,return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[\"description\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "tokenized_data = tokenizer(df_filtered[\"description\"].to_list(), return_tensors=\"np\", padding=True)\n",
    "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
    "tokenized_data = dict(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot generate a hashable key for IteratorSpec(({'input_ids': TensorSpec(shape=(None, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 19), dtype=tf.float32, name=None)),) because the _serialize() method returned an unsupproted value of type <class 'transformers.tokenization_utils_base.BatchEncoding'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m3e-5\u001b[39m))  \u001b[38;5;66;03m# No loss argument!\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tokenized_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(X)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_cache.py:175\u001b[0m, in \u001b[0;36mFunctionCacheKey.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 175\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures_signature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/function/trace_type/default_types.py:207\u001b[0m, in \u001b[0;36mTuple.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/function/trace_type/default_types.py:207\u001b[0m, in \u001b[0;36mTuple.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/core/function/trace_type/default_types.py:601\u001b[0m, in \u001b[0;36mReference.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 601\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot generate a hashable key for IteratorSpec(({'input_ids': TensorSpec(shape=(None, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 19), dtype=tf.float32, name=None)),) because the _serialize() method returned an unsupproted value of type <class 'transformers.tokenization_utils_base.BatchEncoding'>"
     ]
    }
   ],
   "source": [
    "# Load and compile our model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "# Lower learning rates are often better for fine-tuning transformers\n",
    "model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "tokenized_data = dict(X)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([142936, 113818,  43577, ..., 103694, 131932, 121958])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2672\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m-> 2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2674\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2673\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2674\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2675\u001b[0m     )\n\u001b[1;32m   2676\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/__init__.py:355\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/utils/__init__.py:184\u001b[0m, in \u001b[0;36m_array_indexing\u001b[0;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    183\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:906\u001b[0m, in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    901\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    904\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[1;32m    905\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([142936, 113818,  43577, ..., 103694, 131932, 121958])"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "array([  101,  3105,  6412,  2050,  2877,  2613,  3776,  3813,  1999,\n",
       "        2047,  3933,  2003,  6224,  2019,  3831,  5821, 10669,  2007,\n",
       "        2070,  3325,  1999,  8425,  2640,  1012,  2017,  2097,  2022,\n",
       "        2551,  4876,  2007,  2256,  4569,  1010,  2785,  1010, 12479,\n",
       "        2372,  1997,  1996,  4341,  2136,  1998,  2256,  8790,  3237,\n",
       "        2136,  2006,  1037,  3679,  3978,  1012,  2023,  2003,  2019,\n",
       "        4495,  2000,  2022,  2112,  1997,  1037,  3435,  1011,  3652,\n",
       "        1010,  3811,  9768,  2613,  3776, 20138,  4270,  2007,  1037,\n",
       "        5891,  2005, 11813,  5821,  1998,  9313,  3226,  1997,  6792,\n",
       "        1998, 10502,  1012,  2040,  2017,  2024,  1024,  2017,  2442,\n",
       "        2022,  1037,  2092,  1011,  4114,  1010,  5541,  1010,  4013,\n",
       "       19620,  1010,  3893,  1010,  1998,  2087, 14780,  1010,  2785,\n",
       "        1011, 18627,  2711,  1012,  3531,  1010,  2022,  3625,  1010,\n",
       "       26438,  1010,  1998,  4658,  1011,  2104,  1011,  3778,  1012,\n",
       "        3531,  1010,  2022, 27029,  1999, 18106,  5541,  6112,  1006,\n",
       "       27427,  2229, 23773,  1010, 13825,  1010,  7760, 18471,  1007,\n",
       "        1998,  7513,  2436,  7621,  1012,  2682,  2035,  1010,  2031,\n",
       "       10392,  5510,  1998,  2022,  1037,  2204,  1011, 18627,  1010,\n",
       "        4569,  1011,  8295,  2711,  2040,  7459,  2551,  2007,  2111,\n",
       "        1998,  2003,  9461,  2000,  4553,  1012,  2535,  1024,  2256,\n",
       "        2436,  2003,  1037,  3435,  1011, 13823,  4044,  1012,  2017,\n",
       "        1521,  2222,  2147,  3495,  2007,  1037,  5821,  2136,  1998,\n",
       "       10639,  3679,  2007,  2060,  4563,  3095,  1998,  2256,  2312,\n",
       "        2136,  1997,  6074,  1012,  2023,  6412,  2003,  1037,  4766,\n",
       "       19184,  1010,  2021,  2115,  4813,  1998,  5426,  2097,  2022,\n",
       "        2641,  1999,  2054,  2017,  2147,  2006,  1998,  2004,  1996,\n",
       "        2535, 19852,  2015,  2058,  2051,  1012,  4005,  5375,  1011,\n",
       "        4374,  1004, 10939,  5821, 11186,  2013,  6074,  1011,  2650,\n",
       "        8518,  1004, 10639,  2007,  5821,  2136,  1004,  6074,  2006,\n",
       "        3570,  1011,  7374,  6140,  4475,  1998,  5751,  2005,  2330,\n",
       "        3506,  1011, 12040,  4449,  2000, 23557,  1004, 10639,  1004,\n",
       "        2650, 15117, 28745, 20721,  2640,  1004, 16140,  1011,  6605,\n",
       "        4435,  5656,  1998, 24732,  2083,  4037,  1010,  2591,  2865,\n",
       "        1010,  6876,  1010,  3784,  6475,  1010,  6140, 11073,  1998,\n",
       "        2824,  1011,  4374,  1010, 10939,  1010,  1998,  3188, 25090,\n",
       "        4371,  5821, 11186,  2013,  6074,  1011, 13883,  4005,  2640,\n",
       "       11186,  2164,  2695, 17965,  1010,  5751,  1010, 10373,  5821,\n",
       "        1998,  3200, 22953, 20760,  6072,  2478,  3653,  1011,  4493,\n",
       "       23561,  2015,  1998,  4526,  7661,  5617,  1011,  5441,  4435,\n",
       "        7045,  1998, 12391,  6764, 18697,  7666,  1004,  2451,  1011,\n",
       "        2933,  1998, 15389,  2824,  1998, 15365,  1011,  6133, 10402,\n",
       "        1004, 17088,  2005,  2724,  4041,  1004, 12026,  6499,  3126,\n",
       "        2194,  2003,  5462,  2000,  4526,  1037,  7578,  4044,  1998,\n",
       "        2003,  7098,  2000,  2022,  2019,  5020,  4495, 11194,  1012,\n",
       "        2035,  4591, 17362,  2097,  4374,  9584,  2005,  6107,  2302,\n",
       "        7634,  2000,  2679,  1010,  3609,  1010,  4676,  1010,  5907,\n",
       "        1010,  5907,  4767,  2030,  3670,  1010,  4424, 10296,  1010,\n",
       "        2120,  4761,  1010, 14471,  1010, 11980,  1010,  2287,  1010,\n",
       "        2030,  8003,  3570,  1012,  3105,  2828,  1024,  2440,  1011,\n",
       "        2051,  3477,  1024,  1002,  2324,  1011,  2322,  1013,  3178,\n",
       "        3517,  2847,  1024,  3486,  1516,  3429,  2566,  2733,  6666,\n",
       "        1024,  3825,  2051, 12446,  7690,  9307,  1024,  1022,  3178,\n",
       "        5670, 11442,  4710,  2000,  5958, 10288,  4842, 13684,  1024,\n",
       "        5821,  1024,  1015,  2095,  1006,  6871,  1007,  8425,  2640,\n",
       "        1024,  1016,  2086,  1006,  6871,  1007,  2147,  3295,  1024,\n",
       "        1999,  2711,   102,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3667/3667 [==============================] - 2s 378us/step - loss: 3008.6499 - accuracy: 0.1399 - val_loss: 1352.7305 - val_accuracy: 0.1426\n",
      "Epoch 2/10\n",
      "3667/3667 [==============================] - 1s 350us/step - loss: 1276.9083 - accuracy: 0.1410 - val_loss: 1292.6260 - val_accuracy: 0.1070\n",
      "Epoch 3/10\n",
      "3667/3667 [==============================] - 1s 338us/step - loss: 1274.0935 - accuracy: 0.1410 - val_loss: 1177.7609 - val_accuracy: 0.1469\n",
      "Epoch 4/10\n",
      "3667/3667 [==============================] - 1s 344us/step - loss: 1264.6128 - accuracy: 0.1421 - val_loss: 1276.5544 - val_accuracy: 0.1404\n",
      "Epoch 5/10\n",
      "3667/3667 [==============================] - 1s 337us/step - loss: 1265.7806 - accuracy: 0.1422 - val_loss: 1228.2594 - val_accuracy: 0.0989\n",
      "Epoch 6/10\n",
      "3667/3667 [==============================] - 1s 337us/step - loss: 1252.2401 - accuracy: 0.1405 - val_loss: 1330.3905 - val_accuracy: 0.1115\n",
      "Epoch 7/10\n",
      "3667/3667 [==============================] - 1s 344us/step - loss: 1281.9220 - accuracy: 0.1410 - val_loss: 1266.7622 - val_accuracy: 0.1416\n",
      "Epoch 8/10\n",
      "3667/3667 [==============================] - 1s 338us/step - loss: 1282.5883 - accuracy: 0.1420 - val_loss: 1466.0522 - val_accuracy: 0.1022\n",
      "Epoch 9/10\n",
      "3667/3667 [==============================] - 1s 337us/step - loss: 1269.1030 - accuracy: 0.1415 - val_loss: 1221.8574 - val_accuracy: 0.1356\n",
      "Epoch 10/10\n",
      "3667/3667 [==============================] - 1s 346us/step - loss: 1277.6990 - accuracy: 0.1411 - val_loss: 1346.4362 - val_accuracy: 0.1524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7236782680>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = Sequential()\n",
    "seq.add(Dense(19, activation=\"softmax\", input_shape=(512,)))\n",
    "seq.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "seq.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dbf7ceeb364546b4076c0e2d959b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f59c1f2229419f86be2e114ec83d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
